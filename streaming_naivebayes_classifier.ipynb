{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scalable Naive Bayes Classification Algorithm"
      ],
      "metadata": {
        "id": "1qEpVit_ytfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an outline of a scalable Naive Bayes classification algorithm that requires just a single scan of the entire dataset and can be modified to deal with large databases.\n",
        "\n",
        "It is a streaming version of Naive Bayes that updates probabilities incrementally as new data arrives. This approach is suitable for situations where it is not feasible to store the entire dataset in memory, and the model needs to adapt to a continuous stream of data.\n",
        "\n",
        "It's worth noting that Naive Bayes is generally not well-suited for boosting. Boosting algorithms like AdaBoost typically work well with weak learners that have varying degrees of accuracy. Since Naive Bayes assumes feature independence, creating an ensemble of Naive Bayes classifiers may not lead to significant improvements, as they all make similar independence assumptions."
      ],
      "metadata": {
        "id": "6JtqKGc4y8Bc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming Naive Bayes Classification Algorithm"
      ],
      "metadata": {
        "id": "9KMa-2BOzq2-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BqkfM65aygek"
      },
      "outputs": [],
      "source": [
        "class StreamingNaiveBayes:\n",
        "    def __init__(self, classes):\n",
        "        self.classes = classes\n",
        "        self.class_counts = {c: 0 for c in classes}\n",
        "        self.feature_counts = {c: {} for c in classes}\n",
        "        self.class_probabilities = {c: 0 for c in classes}\n",
        "\n",
        "    def update_model(self, instance, label):\n",
        "        # Update class counts\n",
        "        self.class_counts[label] += 1\n",
        "\n",
        "        # Update feature counts for each class\n",
        "        for feature, value in instance.items():\n",
        "            if feature not in self.feature_counts[label]:\n",
        "                self.feature_counts[label][feature] = {}\n",
        "            if value not in self.feature_counts[label][feature]:\n",
        "                self.feature_counts[label][feature][value] = 0\n",
        "            self.feature_counts[label][feature][value] += 1\n",
        "\n",
        "    def update_class_probabilities(self):\n",
        "        total_instances = sum(self.class_counts.values())\n",
        "        for label in self.classes:\n",
        "            self.class_probabilities[label] = self.class_counts[label] / total_instances\n",
        "\n",
        "    def predict(self, instance):\n",
        "        # Calculate posterior probabilities for each class\n",
        "        posteriors = {label: 1 for label in self.classes}\n",
        "        for label in self.classes:\n",
        "            for feature, value in instance.items():\n",
        "                if value in self.feature_counts[label][feature]:\n",
        "                    likelihood = self.feature_counts[label][feature][value] / self.class_counts[label]\n",
        "                else:\n",
        "                    # Smoothing for unseen values\n",
        "                    likelihood = 1 / (self.class_counts[label] + 1)\n",
        "                posteriors[label] *= likelihood\n",
        "\n",
        "            # Multiply by class probability\n",
        "            posteriors[label] *= self.class_probabilities[label]\n",
        "\n",
        "        # Return the class with the highest posterior probability\n",
        "        return max(posteriors, key=posteriors.get)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example usage:"
      ],
      "metadata": {
        "id": "koBwur5Mz5O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "classes = ['spam', 'ham']\n",
        "model = StreamingNaiveBayes(classes)\n",
        "\n",
        "# Update the model with instances\n",
        "instance1 = {'word1': 'hello', 'word2': 'world'}\n",
        "model.update_model(instance1, 'ham')\n",
        "\n",
        "instance2 = {'word1': 'discount', 'word2': 'offer'}\n",
        "model.update_model(instance2, 'spam')\n",
        "\n",
        "# Update class probabilities\n",
        "model.update_class_probabilities()\n",
        "\n",
        "# Make predictions\n",
        "new_instance = {'word1': 'hello', 'word2': 'world'}\n",
        "prediction = model.predict(new_instance)\n",
        "print(\"Predicted class:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vholjcDaz65b",
        "outputId": "ceff6456-23d2-4639-f3f8-b878f59b9e2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: ham\n"
          ]
        }
      ]
    }
  ]
}